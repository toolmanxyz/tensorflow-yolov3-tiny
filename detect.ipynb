{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/working\n!rm -rf tf\n!git clone https://github.com/hunglc007/tensorflow-yolov4-tflite.git tf\n!cp /kaggle/input/yolov3/yolo-obj_last-CAM_4min.weights /kaggle/working/tf/data/yolo-obj_last.weights\n# !cp /kaggle/input/yolov4/yolo-obj_last_5.weights /kaggle/working/tf/data/yolo-obj_last.weights","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 152\n!sed -i \"s/c1, c2 = (coor\\[1\\], coor\\[0\\]), (coor\\[3\\], coor\\[2\\])/c1, c2 = (int(coor\\[1\\]), int(coor\\[0\\])), (int(coor\\[3\\]), int(coor\\[2\\]))/g\" /kaggle/working/tf/core/utils.py\n# 159\n!sed -i \"s/cv2.rectangle(image, c1, (np.float32(c3\\[0\\]), np.float32(c3\\[1\\])), bbox_color, -1) #filled/cv2.rectangle(image, c1, (int(np.float32(c3\\[0\\])), int(np.float32(c3\\[1\\]))), bbox_color, -1)/\" /kaggle/working/tf/core/utils.py\n# 161\n!sed -i \"s/cv2.putText(image, bbox_mess, (c1\\[0\\], np.float32(c1\\[1\\] - 2)), cv2.FONT_HERSHEY_SIMPLEX,/cv2.putText(image, bbox_mess, (c1\\[0\\], int(np.float32(c1\\[1\\] - 2))), cv2.FONT_HERSHEY_SIMPLEX,/\" /kaggle/working/tf/core/utils.py\n# 162\n!sed -i \"s/fontScale, (0, 0, 0), bbox_thick \\/\\/ 2, lineType=cv2.LINE_AA)/fontScale, (0, 0, 0), bbox_thick \\/\\/ 2, lineType=cv2.LINE_AA)/\" /kaggle/working/tf/core/utils.py\n!printf \"Done\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!printf \"person\" > /kaggle/working/tf/data/class.names\n!sed -i \"s/.\\/data\\/classes\\/coco.names/.\\/data\\/class.names/\" /kaggle/working/tf/core/config.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/tf\n# Convert darknet weights to tensorflow\n!python save_model.py --weights ./data/yolo-obj_last.weights --output ./checkpoints/yolov4-416 --input_size 416 --model yolov3 --tiny true\n# !python save_model.py --weights ./data/yolo-obj_last.weights --output ./checkpoints/yolov4-416 --input_size 608 --model yolov4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://github.com/hunglc007/tensorflow-yolov4-tflite/pull/346/files/0e5d29e66c263318f166919eea2041630118a179\n!sed -i \"s/saved_model_loaded = tf.saved_model.load(FLAGS.weights, tags=\\[tag_constants.SERVING\\])/# saved_model_loaded = tf.saved_model.load(FLAGS.weights, tags=\\[tag_constants.SERVING\\])/\" detectvideo.py\n!sed -i \"s/infer = saved_model_loaded.signatures\\['serving_default'\\]/# infer = saved_model_loaded.signatures\\['serving_default'\\]\\n        infer = tf.keras.models.load_model(FLAGS.weights)\\n/\" detectvideo.py\n!sed -i \"s/for key, value in pred_bbox.items():/# for key, value in pred_bbox.items():\\n            boxes = pred_bbox\\[:, :, 0:4\\]\\n            pred_conf = pred_bbox\\[:, :, 4:\\]/\" detectvideo.py\n!sed -i \"s/pred_conf = value\\[:, :, 4:\\]/# pred_conf = value\\[:, :, 4:\\]/\" detectvideo.py\n!sed -i \"s/boxes = value\\[:, :, 0:4\\]/# boxes = value\\[:, :, 0:4\\]/\" detectvideo.py\n!printf \"Done\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm result.png","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sed -i \"s/image.show()/# image.show()/\" ./detect.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sed -i \"s/frame_id = 0/frame_id = 0\\n    print(vid.get(cv2.CAP_PROP_FRAME_COUNT))/\" detectvideo.py\n!sed -i \"s/print(info)/print(info + \" \" + frame_id)/\" detectvideo.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VIDEO_NAME=\"CAM1-24\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python detect.py --weights ./checkpoints/yolov4-416 --size 608 --model yolov4 --tiny false --image /kaggle/input/testimage/030.jpg --output ./030.jpg\n# !export FILE=001 && python detect.py --weights ./checkpoints/yolov4-416 --size 416 --model yolov3 --tiny true --image /kaggle/input/testimage/$FILE.jpg --output ./output/$FILE.jpg\n# !python detectvideo.py --weights ./checkpoints/yolov4-416 --size 416 --model yolov3 --tiny true --video /kaggle/input/testvideo/VIRAT_S_010204_05_000856_000890.mp4 --dis_cv2_window True --output ./streat-kaggle-last_5-gpu.mp4\n# !python detectvideo.py --weights ./checkpoints/yolov4-416 --size 416 --model yolov3 --tiny true --video \"/kaggle/input/testvideo/2022-05-04 01-48-32.mkv\" --dis_cv2_window True --output ./kaggle.mp4\n!python detectvideo.py --weights ./checkpoints/yolov4-416 --size 416 --model yolov3 --tiny true --video /kaggle/input/testvideo/{VIDEO_NAME}.mp4 --dis_cv2_window True --output ./{VIDEO_NAME}-tinyv3.mp4","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf video.zip\n!zip video.zip {VIDEO_NAME}-tinyv3.mp4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip image.zip ./output/*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<button><a href=\"./tf/video.zip\"> Download File </a></button>","metadata":{}},{"cell_type":"markdown","source":"=================================================","metadata":{}},{"cell_type":"code","source":"NAME=\"CGS\"\n!mkdir {NAME}\n!echo \"CGS123\" | grep {NAME} > {NAME}/{NAME}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat CGS/CGS","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
